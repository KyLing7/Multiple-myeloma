{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7105b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "✅ Random Forest 5-Fold 平均评估结果：\n",
      "ROC_AUC: 0.8731\n",
      "ACCURACY: 0.7558\n",
      "F1: 0.8080\n",
      "PRECISION: 0.7177\n",
      "RECALL: 0.9253\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# === 1. 读取表达矩阵（仅保留 AUC > 0.6 的基因）===\n",
    "data_path = \"merged_train.csv\"  # 请按你的路径修改\n",
    "X = pd.read_csv(data_path)\n",
    "\n",
    "# === 2. 读取 metadata 并整合样本标签 ===\n",
    "metadata_dir = \"../metadata\"\n",
    "metadata_files = [\n",
    "    \"E-MTAB-316_metadata.csv\",\n",
    "    \"GSE5900_metadata.csv\",\n",
    "    \"GSE6477_metadata.csv\",\n",
    "    \"GSE13591_metadata.csv\"\n",
    "]\n",
    "\n",
    "metadata_all = pd.concat([\n",
    "    pd.read_csv(os.path.join(metadata_dir, file))\n",
    "    for file in metadata_files\n",
    "], ignore_index=True)\n",
    "\n",
    "# 仅保留 SampleID 和 label 两列，并排除 label 缺失\n",
    "metadata_all = metadata_all[[\"SampleID\", \"label\"]]\n",
    "metadata_all = metadata_all[metadata_all[\"label\"].notna()]\n",
    "\n",
    "# === 3. 构建 y ===\n",
    "label_df = metadata_all.set_index(\"SampleID\")\n",
    "y = X[\"SampleID\"].map(label_df[\"label\"])\n",
    "\n",
    "# === 4. 丢弃无标签的样本 ===\n",
    "valid_idx = y.notna()\n",
    "y = y[valid_idx].astype(int)\n",
    "X_model = X.loc[valid_idx].drop(columns=[\"SampleID\", \"Dataset\"], errors=\"ignore\")\n",
    "\n",
    "# === 5. 构建 Pipeline：标准化 + 随机森林 ===\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# === 6. 设置调参网格 ===\n",
    "param_grid = {\n",
    "    \"clf__n_estimators\": [100, 200, 500],\n",
    "    \"clf__max_depth\": [None, 10, 20, 30],\n",
    "    \"clf__min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "# === 7. 进行网格搜索（5-Fold）===\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_model, y)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# === 8. 手动 5-Fold 验证评分 ===\n",
    "scores = {\n",
    "    \"ROC_AUC\": [],\n",
    "    \"ACCURACY\": [],\n",
    "    \"F1\": [],\n",
    "    \"PRECISION\": [],\n",
    "    \"RECALL\": []\n",
    "}\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_model, y):\n",
    "    X_train, X_test = X_model.iloc[train_idx], X_model.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    scores[\"ROC_AUC\"].append(roc_auc_score(y_test, y_proba))\n",
    "    scores[\"ACCURACY\"].append(accuracy_score(y_test, y_pred))\n",
    "    scores[\"F1\"].append(f1_score(y_test, y_pred))\n",
    "    scores[\"PRECISION\"].append(precision_score(y_test, y_pred))\n",
    "    scores[\"RECALL\"].append(recall_score(y_test, y_pred))\n",
    "\n",
    "# === 9. 输出评估结果 ===\n",
    "print(\"\\n✅ Random Forest 5-Fold 平均评估结果：\")\n",
    "for metric, values in scores.items():\n",
    "    print(f\"{metric}: {np.mean(values):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb2aded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 模型已保存为 random_forest_allgenesmodel.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 10. 保存模型 ===\n",
    "joblib.dump(best_model, \"random_forest_allgenesmodel.pkl\")\n",
    "print(\"\\n✅ 模型已保存为 random_forest_allgenesmodel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4dda542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylin/.pyenv/versions/3.10.13/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:05:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[19:05:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:05:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:05:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:05:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:05:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "/Users/kylin/.pyenv/versions/3.10.13/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:05:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[19:06:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "/Users/kylin/.pyenv/versions/3.10.13/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:06:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[19:06:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "/Users/kylin/.pyenv/versions/3.10.13/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:06:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[19:06:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:06:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "/Users/kylin/.pyenv/versions/3.10.13/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:06:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[19:07:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:07:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:07:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:07:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:07:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Stacking Classifier 5-Fold 评估结果:\n",
      "ROC_AUC: 0.8618\n",
      "ACCURACY: 0.7420\n",
      "F1: 0.8006\n",
      "PRECISION: 0.7046\n",
      "RECALL: 0.9296\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, accuracy_score, f1_score, precision_score,\n",
    "    recall_score, roc_auc_score\n",
    ")\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# === 1. 读取表达数据 ===\n",
    "data_path = \"merged_train.csv\"\n",
    "X = pd.read_csv(data_path)\n",
    "\n",
    "# === 2. 读取标签 metadata ===\n",
    "metadata_dir = \"../../metadata\"\n",
    "metadata_files = [\n",
    "    \"E-MTAB-316_metadata.csv\",\n",
    "    \"GSE5900_metadata.csv\",\n",
    "    \"GSE6477_metadata.csv\",\n",
    "    \"GSE13591_metadata.csv\"\n",
    "]\n",
    "\n",
    "metadata_all = pd.concat([\n",
    "    pd.read_csv(os.path.join(metadata_dir, file))\n",
    "    for file in metadata_files\n",
    "], ignore_index=True)\n",
    "\n",
    "metadata_all = metadata_all[[\"SampleID\", \"label\"]]\n",
    "metadata_all = metadata_all[metadata_all[\"label\"].notna()]\n",
    "\n",
    "# === 3. 构建标签向量 y ===\n",
    "label_df = metadata_all.set_index(\"SampleID\")\n",
    "y = X[\"SampleID\"].map(label_df[\"label\"])\n",
    "valid_idx = y.notna()\n",
    "y = y[valid_idx].astype(int)\n",
    "X_model = X.loc[valid_idx].drop(columns=[\"SampleID\", \"Dataset\"], errors=\"ignore\")\n",
    "\n",
    "# === 4. 构建 stacking 模型 ===\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegressionCV(cv=5, max_iter=1000)\n",
    "\n",
    "stacking = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=final_estimator,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        passthrough=False\n",
    "    ))\n",
    "])\n",
    "\n",
    "# === 5. 定义评分指标 ===\n",
    "scoring = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# === 6. 交叉验证 ===\n",
    "results = cross_validate(stacking, X_model, y, cv=cv, scoring=scoring, return_train_score=False)\n",
    "\n",
    "# === 7. 输出平均结果 ===\n",
    "print(\"\\n✅ Stacking Classifier 5-Fold 评估结果:\")\n",
    "for metric in scoring.keys():\n",
    "    score_values = results[f'test_{metric}']\n",
    "    print(f\"{metric.upper()}: {np.mean(score_values):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660fdb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylin/.pyenv/versions/3.10.13/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:07:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[19:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[19:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 模型已保存为 stacking_allgenesmodel.pkl\n"
     ]
    }
   ],
   "source": [
    "# === 8. 训练全量模型并保存 ===\n",
    "stacking.fit(X_model, y)\n",
    "joblib.dump(stacking, \"stacking_allgenesmodel.pkl\")\n",
    "print(\"\\n✅ 模型已保存为 stacking_allgenesmodel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "216fdccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Model  Accuracy        F1  Precision    Recall   ROC AUC\n",
      "0  RandomForest  0.700000  0.797927   0.735669  0.871698  0.687064\n",
      "1      Stacking  0.684615  0.784588   0.732026  0.845283  0.697419\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# 1. 模型路径（仅保留两个）\n",
    "model_paths = {\n",
    "    \"RandomForest\": \"random_forest_allgenesmodel.pkl\",\n",
    "    \"Stacking\": \"stacking_allgenesmodel.pkl\"\n",
    "}\n",
    "\n",
    "# 2. 加载测试集\n",
    "test_df = pd.read_csv(\"merged_test.csv\")\n",
    "\n",
    "# 3. 加载标签\n",
    "metadata_dir = \"../../metadata\"\n",
    "metadata_files = [\n",
    "    \"E-MTAB-317_metadata.csv\",\n",
    "    \"GSE2113_metadata.csv\",\n",
    "    \"GSE235356_metadata.csv\",\n",
    "]\n",
    "metadata_all = pd.concat([\n",
    "    pd.read_csv(os.path.join(metadata_dir, f))[[\"SampleID\", \"label\"]] for f in metadata_files\n",
    "])\n",
    "metadata_all = metadata_all.dropna(subset=[\"label\"])\n",
    "metadata_all[\"label\"] = metadata_all[\"label\"].astype(int)\n",
    "\n",
    "# 4. 构建测试集 X 和 y\n",
    "label_df = metadata_all.set_index(\"SampleID\")\n",
    "y_test = test_df[\"SampleID\"].map(label_df[\"label\"])\n",
    "valid_idx = y_test.notna()\n",
    "X_test = test_df.loc[valid_idx].drop(columns=[\"SampleID\"])\n",
    "y_test = y_test[valid_idx].astype(int)\n",
    "\n",
    "# 5. 测试函数\n",
    "def evaluate_model(name, model, X, y):\n",
    "    if hasattr(model, \"feature_names_in_\"):\n",
    "        X = X.loc[:, model.feature_names_in_]\n",
    "    else:\n",
    "        try:\n",
    "            scaler = model.named_steps[\"scaler\"]\n",
    "            X = X.loc[:, scaler.feature_names_in_]\n",
    "        except:\n",
    "            pass\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y, y_pred),\n",
    "        \"F1\": f1_score(y, y_pred),\n",
    "        \"Precision\": precision_score(y, y_pred),\n",
    "        \"Recall\": recall_score(y, y_pred),\n",
    "        \"ROC AUC\": roc_auc_score(y, y_prob) if y_prob is not None else \"N/A\"\n",
    "    }\n",
    "\n",
    "# 6. 批量测试模型\n",
    "results = []\n",
    "for name, path in model_paths.items():\n",
    "    model = joblib.load(path)\n",
    "    score = evaluate_model(name, model, X_test, y_test)\n",
    "    results.append(score)\n",
    "\n",
    "# 7. 输出\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b15b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stacking model with interaction features...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# === 1. 加载训练集和测试集 ===\n",
    "train_df = pd.read_csv(\"merged_train.csv\")\n",
    "test_df = pd.read_csv(\"merged_test.csv\")\n",
    "\n",
    "# === 2. 合并所有 metadata 获取标签 ===\n",
    "metadata_dir = \"../../metadata\"\n",
    "metadata_files = [f for f in os.listdir(metadata_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "metadata_all = pd.concat([\n",
    "    pd.read_csv(os.path.join(metadata_dir, f))[[\"SampleID\", \"label\"]] for f in metadata_files\n",
    "])\n",
    "metadata_all = metadata_all.dropna(subset=[\"label\"])\n",
    "metadata_all[\"label\"] = metadata_all[\"label\"].astype(int)\n",
    "label_df = metadata_all.set_index(\"SampleID\")\n",
    "\n",
    "# === 3. 构造 X_train, y_train, X_test, y_test ===\n",
    "y_train = train_df[\"SampleID\"].map(label_df[\"label\"])\n",
    "y_test = test_df[\"SampleID\"].map(label_df[\"label\"])\n",
    "\n",
    "train_valid = y_train.notna()\n",
    "test_valid = y_test.notna()\n",
    "\n",
    "X_train = train_df.loc[train_valid].drop(columns=[\"SampleID\"])\n",
    "X_test = test_df.loc[test_valid].drop(columns=[\"SampleID\"])\n",
    "\n",
    "# 🚫 防止非数值型特征干扰\n",
    "X_train = X_train.select_dtypes(include=[\"number\"])\n",
    "X_test = X_test.select_dtypes(include=[\"number\"])\n",
    "\n",
    "y_train = y_train[train_valid].astype(int)\n",
    "y_test = y_test[test_valid].astype(int)\n",
    "\n",
    "# === 4. 构建带乘积交互项的 base 模型 Pipeline ===\n",
    "def make_base_model(clf):\n",
    "    return Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", clf)\n",
    "    ])\n",
    "\n",
    "base_learners = [\n",
    "    (\"rf\", make_base_model(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    (\"svm\", make_base_model(SVC(kernel='linear', probability=True)))\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegression(max_iter=1000)\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=final_estimator,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === 5. 模型训练 ===\n",
    "print(\"Training stacking model with interaction features...\")\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# === 6. 保存模型 ===\n",
    "joblib.dump(stacking_model, \"stacking_with_interactions.pkl\")\n",
    "\n",
    "# === 7. 模型评估 ===\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "y_prob = stacking_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "results = {\n",
    "    \"Model\": \"Stacking_with_Interaction\",\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_prob)\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "print(\"\\n=== Evaluation on Test Set ===\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40401247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb8e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432b8c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
